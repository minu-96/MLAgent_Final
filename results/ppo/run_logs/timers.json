{
    "name": "root",
    "gauges": {
        "StealthAgent.Policy.Entropy.mean": {
            "value": 0.9093223214149475,
            "min": 0.9093223214149475,
            "max": 1.5601756572723389,
            "count": 3
        },
        "StealthAgent.Policy.Entropy.sum": {
            "value": 90859.484375,
            "min": 90859.484375,
            "max": 129260.5546875,
            "count": 3
        },
        "StealthAgent.Step.mean": {
            "value": 299954.0,
            "min": 99974.0,
            "max": 299954.0,
            "count": 3
        },
        "StealthAgent.Step.sum": {
            "value": 299954.0,
            "min": 99974.0,
            "max": 299954.0,
            "count": 3
        },
        "StealthAgent.Policy.ExtrinsicValueEstimate.mean": {
            "value": -2.314319610595703,
            "min": -2.544110059738159,
            "max": -2.1399435997009277,
            "count": 3
        },
        "StealthAgent.Policy.ExtrinsicValueEstimate.sum": {
            "value": -4464.32275390625,
            "min": -4721.8681640625,
            "max": -2970.24169921875,
            "count": 3
        },
        "StealthAgent.Environment.EpisodeLength.mean": {
            "value": 129.13878080415046,
            "min": 129.13878080415046,
            "max": 439.54594594594596,
            "count": 3
        },
        "StealthAgent.Environment.EpisodeLength.sum": {
            "value": 99566.0,
            "min": 81316.0,
            "max": 99764.0,
            "count": 3
        },
        "StealthAgent.Environment.CumulativeReward.mean": {
            "value": -6.406871906359681,
            "min": -22.03268376737833,
            "max": -6.406871906359681,
            "count": 3
        },
        "StealthAgent.Environment.CumulativeReward.sum": {
            "value": -4939.698239803314,
            "min": -5097.75359249115,
            "max": -4054.0138131976128,
            "count": 3
        },
        "StealthAgent.Policy.ExtrinsicReward.mean": {
            "value": -6.406871906359681,
            "min": -22.03268376737833,
            "max": -6.406871906359681,
            "count": 3
        },
        "StealthAgent.Policy.ExtrinsicReward.sum": {
            "value": -4939.698239803314,
            "min": -5097.75359249115,
            "max": -4054.0138131976128,
            "count": 3
        },
        "StealthAgent.Losses.PolicyLoss.mean": {
            "value": 0.02495054610694448,
            "min": 0.021899418813107464,
            "max": 0.02495054610694448,
            "count": 3
        },
        "StealthAgent.Losses.PolicyLoss.sum": {
            "value": 0.24950546106944482,
            "min": 0.19410915443052848,
            "max": 0.24950546106944482,
            "count": 3
        },
        "StealthAgent.Losses.ValueLoss.mean": {
            "value": 0.3693569502234459,
            "min": 0.13716869921578717,
            "max": 0.3693569502234459,
            "count": 3
        },
        "StealthAgent.Losses.ValueLoss.sum": {
            "value": 3.693569502234459,
            "min": 1.0973495937262974,
            "max": 3.693569502234459,
            "count": 3
        },
        "StealthAgent.Policy.LearningRate.mean": {
            "value": 0.0002985094972968344,
            "min": 0.0002985094972968344,
            "max": 0.0002996180918773027,
            "count": 3
        },
        "StealthAgent.Policy.LearningRate.sum": {
            "value": 0.0029850949729683437,
            "min": 0.002396944735018422,
            "max": 0.0029850949729683437,
            "count": 3
        },
        "StealthAgent.Policy.Epsilon.mean": {
            "value": 0.1995031656,
            "min": 0.1995031656,
            "max": 0.19987269725000006,
            "count": 3
        },
        "StealthAgent.Policy.Epsilon.sum": {
            "value": 1.995031656,
            "min": 1.5989815780000005,
            "max": 1.995031656,
            "count": 3
        },
        "StealthAgent.Policy.Beta.mean": {
            "value": 0.0004975655114399999,
            "min": 0.0004975655114399999,
            "max": 0.0004993762165250001,
            "count": 3
        },
        "StealthAgent.Policy.Beta.sum": {
            "value": 0.004975655114399999,
            "min": 0.003995009732200001,
            "max": 0.004975655114399999,
            "count": 3
        },
        "StealthAgent.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 3
        },
        "StealthAgent.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 3
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1765938626",
        "python_version": "3.8.0 (default, Nov  6 2019, 16:00:02) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\NSU\\anaconda3\\envs\\mlpy38\\Scripts\\mlagents-learn configuration.yaml --resume",
        "mlagents_version": "0.27.0",
        "mlagents_envs_version": "0.27.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.0.0+cu118",
        "numpy_version": "1.19.0",
        "end_time_seconds": "1765938933"
    },
    "total": 306.7823037,
    "count": 1,
    "self": 0.011078699999984565,
    "children": {
        "run_training.setup": {
            "total": 0.054331099999999966,
            "count": 1,
            "self": 0.054331099999999966
        },
        "TrainerController.start_learning": {
            "total": 306.7168939,
            "count": 1,
            "self": 0.5056507000002739,
            "children": {
                "TrainerController._reset_env": {
                    "total": 5.9435712999999994,
                    "count": 1,
                    "self": 5.9435712999999994
                },
                "TrainerController.advance": {
                    "total": 300.01019139999977,
                    "count": 29514,
                    "self": 0.5263220000002207,
                    "children": {
                        "env_step": {
                            "total": 223.2375043999988,
                            "count": 29514,
                            "self": 134.38441920000417,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 88.51979379999653,
                                    "count": 29514,
                                    "self": 1.305103599994851,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 87.21469020000168,
                                            "count": 28397,
                                            "self": 45.09868270000112,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 42.11600750000056,
                                                    "count": 28397,
                                                    "self": 42.11600750000056
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.333291399998088,
                                    "count": 29513,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 299.0451973000004,
                                            "count": 29513,
                                            "is_parallel": true,
                                            "self": 193.05436860000185,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00041729999999962075,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00021089999999990283,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00020639999999971792,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00020639999999971792
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 105.99041139999854,
                                                    "count": 29513,
                                                    "is_parallel": true,
                                                    "self": 2.6994957999979476,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 3.780119500002007,
                                                            "count": 29513,
                                                            "is_parallel": true,
                                                            "self": 3.780119500002007
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 90.63680480000008,
                                                            "count": 29513,
                                                            "is_parallel": true,
                                                            "self": 90.63680480000008
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 8.873991299998508,
                                                            "count": 29513,
                                                            "is_parallel": true,
                                                            "self": 4.019160899991181,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 4.854830400007327,
                                                                    "count": 59026,
                                                                    "is_parallel": true,
                                                                    "self": 4.854830400007327
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 76.24636500000071,
                            "count": 29513,
                            "self": 0.6929284000036802,
                            "children": {
                                "process_trajectory": {
                                    "total": 28.895111699997084,
                                    "count": 29513,
                                    "self": 28.895111699997084
                                },
                                "_update_policy": {
                                    "total": 46.65832489999995,
                                    "count": 27,
                                    "self": 35.29026189999959,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 11.368063000000351,
                                            "count": 810,
                                            "self": 11.368063000000351
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 8.000000093488779e-07,
                    "count": 1,
                    "self": 8.000000093488779e-07
                },
                "TrainerController._save_models": {
                    "total": 0.2574796999999762,
                    "count": 1,
                    "self": 0.007103400000005422,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.2503762999999708,
                            "count": 1,
                            "self": 0.2503762999999708
                        }
                    }
                }
            }
        }
    }
}